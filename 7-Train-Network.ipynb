{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Introduct the core topics of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "Details of the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Topic-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Topic-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "activation_function = sigmoid\n",
    "from scipy.stats import truncnorm\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "class NeuralNetwork:\n",
    "        \n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate,\n",
    "                 bias=None\n",
    "                ):  \n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        \n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "            \n",
    "        self.learning_rate = learning_rate \n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "    \n",
    "        \n",
    "    \n",
    "    def create_weight_matrices(self):\n",
    "        \"\"\" A method to initialize the weight matrices of the neural \n",
    "        network with optional bias nodes\"\"\"\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        \n",
    "        rad = 1 / np.sqrt(self.no_of_in_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        self.weights_in_hidden = X.rvs((self.no_of_hidden_nodes, \n",
    "                                       self.no_of_in_nodes + bias_node))\n",
    "        rad = 1 / np.sqrt(self.no_of_hidden_nodes + bias_node)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        self.weights_hidden_out = X.rvs((self.no_of_out_nodes, \n",
    "                                        self.no_of_hidden_nodes + bias_node))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self, input_vector, target_vector):\n",
    "        # input_vector and target_vector can be tuple, list or ndarray\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "                                    \n",
    "            \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        \n",
    "        output_vector1 = np.dot(self.weights_in_hidden, input_vector)\n",
    "        output_vector_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector_hidden = np.concatenate( (output_vector_hidden, [[self.bias]]) )\n",
    "        \n",
    "        \n",
    "        output_vector2 = np.dot(self.weights_hidden_out, output_vector_hidden)\n",
    "        output_vector_network = activation_function(output_vector2)\n",
    "        \n",
    "        output_errors = target_vector - output_vector_network\n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)     \n",
    "        tmp = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
    "        self.weights_hidden_out += tmp\n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.weights_hidden_out.T, output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n",
    "        if self.bias:\n",
    "            x = np.dot(tmp, input_vector.T)[:-1,:]     # ???? last element cut off, ???\n",
    "        else:\n",
    "            x = np.dot(tmp, input_vector.T)\n",
    "        self.weights_in_hidden += self.learning_rate * x\n",
    "        \n",
    "       \n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        \n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector, [1]) )\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        output_vector = np.dot(self.weights_in_hidden, input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector = np.concatenate( (output_vector, [[1]]) )\n",
    "            \n",
    "        output_vector = np.dot(self.weights_hidden_out, output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "    \n",
    "        return output_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(-3, -4), [0, 1]], [(4, 3), [1, 0]], [(-1.5, -3.6), [0, 1]], [(3.2, 4.6), [1, 0]], [(4.3, 4.3), [1, 0]], [(-1, -6), [0, 1]], [(-2.3, -4.3), [0, 1]], [(5, 4), [1, 0]], [(6, 5), [1, 0]], [(7, 4), [1, 0]]]\n"
     ]
    }
   ],
   "source": [
    "class1 = [(3, 4), (4.2, 5.3), (4, 3), (6, 5), (4, 6), (3.7, 5.8),\n",
    "          (3.2, 4.6), (5.2, 5.9), (5, 4), (7, 4), (3, 7), (4.3, 4.3) ] \n",
    "class2 = [(-3, -4), (-2, -3.5), (-1, -6), (-3, -4.3), (-4, -5.6), \n",
    "          (-3.2, -4.8), (-2.3, -4.3), (-2.7, -2.6), (-1.5, -3.6), \n",
    "          (-3.6, -5.6), (-4.5, -4.6), (-3.7, -5.8) ]\n",
    "labeled_data = []\n",
    "for el in class1:\n",
    "    labeled_data.append( [el, [1, 0]])\n",
    "for el in class2:\n",
    "    labeled_data.append([el, [0, 1]])\n",
    "  \n",
    "np.random.shuffle(labeled_data)\n",
    "print(labeled_data[:10])\n",
    "data, labels = zip(*labeled_data)\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[[0.06299157]\n",
      " [0.93901625]]\n",
      "[1 0]\n",
      "[[0.89716614]\n",
      " [0.10315351]]\n",
      "[0 1]\n",
      "[[0.06944914]\n",
      " [0.93208909]]\n",
      "[1 0]\n",
      "[[0.90139844]\n",
      " [0.09953514]]\n",
      "[1 0]\n",
      "[[0.90195385]\n",
      " [0.09877472]]\n",
      "[0 1]\n",
      "[[0.06320614]\n",
      " [0.93835981]]\n",
      "[0 1]\n",
      "[[0.06350804]\n",
      " [0.93831154]]\n",
      "[1 0]\n",
      "[[0.90190626]\n",
      " [0.09872252]]\n",
      "[1 0]\n",
      "[[0.90337007]\n",
      " [0.0973981 ]]\n",
      "[1 0]\n",
      "[[0.90273858]\n",
      " [0.09790953]]\n",
      "[0 1]\n",
      "[[0.06148265]\n",
      " [0.9404527 ]]\n",
      "[1 0]\n",
      "[[0.89945017]\n",
      " [0.10147182]]\n",
      "[1 0]\n",
      "[[0.90320293]\n",
      " [0.09770495]]\n",
      "[1 0]\n",
      "[[0.90347658]\n",
      " [0.09748631]]\n",
      "[0 1]\n",
      "[[0.06238391]\n",
      " [0.93957695]]\n",
      "[0 1]\n",
      "[[0.06054654]\n",
      " [0.94139743]]\n",
      "[0 1]\n",
      "[[0.06742277]\n",
      " [0.93440439]]\n",
      "[1 0]\n",
      "[[0.9030733 ]\n",
      " [0.09777367]]\n",
      "[0 1]\n",
      "[[0.06054621]\n",
      " [0.94137817]]\n",
      "[1 0]\n",
      "[[0.90364451]\n",
      " [0.09719126]]\n",
      "[0 1]\n",
      "[[0.06098652]\n",
      " [0.94104694]]\n",
      "[0 1]\n",
      "[[0.07036944]\n",
      " [0.93215885]]\n",
      "[0 1]\n",
      "[[0.06066714]\n",
      " [0.94125802]]\n",
      "[1 0]\n",
      "[[0.90342287]\n",
      " [0.09746507]]\n"
     ]
    }
   ],
   "source": [
    "simple_network = NeuralNetwork(no_of_in_nodes=2, \n",
    "                               no_of_out_nodes=2, \n",
    "                               no_of_hidden_nodes=10,\n",
    "                               learning_rate=0.1,\n",
    "                               bias=None)\n",
    "    \n",
    "for _ in range(20):\n",
    "    for i in range(len(data)):\n",
    "        simple_network.train(data[i], labels[i])\n",
    "for i in range(len(data)):\n",
    "    print(labels[i])\n",
    "    print(simple_network.run(data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Topic-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Summarize what we have covered in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "List resources that can help further understand the topics in this tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
